import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Assuming your data is loaded into a DataFrame named df
# df = pd.read_csv('your_cantine_data.csv')

# Data Preparation
def prepare_data(df):
    # Convert date to datetime if not already
    df['date'] = pd.to_datetime(df['date'])
    
    # Create additional time-based features that might be useful
    df['week_of_year'] = df['date'].dt.isocalendar().week
    df['is_weekend'] = (df['jour num'] >= 6).astype(int)  # Assuming 6=Saturday, 7=Sunday
    df['is_ramadan'] = (df['hijri month'] == 'Ramadan').astype(int)  # Adjust based on actual hijri month names
    
    # Handle categorical variables (one-hot encoding)
    hijri_month_dummies = pd.get_dummies(df['hijri month'], prefix='hijri_month')
    df = pd.concat([df, hijri_month_dummies], axis=1)
    
    # Drop original hijri month column and other columns that won't be available for prediction
    df = df.drop(['hijri month', 'nb_entrees_HO', 'nb_entrees_cantine', 'raio'], axis=1)
    
    return df

# Prepare the data
df_prepared = prepare_data(df)

# Split into features and target
X = df_prepared.drop('nb_entrees_cantine', axis=1)
y = df_prepared['nb_entrees_cantine']

# Train-test split (chronological split)
split_date = df_prepared['date'].max() - timedelta(days=180)  # Last 6 months for testing
X_train = X[X['date'] <= split_date]
X_test = X[X['date'] > split_date]
y_train = y[X['date'] <= split_date]
y_test = y[X['date'] > split_date]

# Drop date column as we've extracted all temporal features
X_train = X_train.drop('date', axis=1)
X_test = X_test.drop('date', axis=1)

# Now let's create a solution using Azure OpenAI for forecasting
import openai
from openai import AzureOpenAI

# Set up Azure OpenAI client
client = AzureOpenAI(
    api_key=AZURE_AOAI_API_KEY,  
    api_version=AZURE_AOAI_API_VERSION,
    azure_endpoint=APIGEE_ENDPOINT  # This might need adjustment based on your setup
)

# Since we're dealing with time series forecasting, we'll use a hybrid approach:
# 1. Use traditional time series features
# 2. Use Azure OpenAI to help with feature importance and pattern recognition

def create_prompt_for_analysis(X_train, y_train, future_features):
    """
    Create a prompt for Azure OpenAI to analyze patterns and provide insights
    """
    # Sample some of the data to include in the prompt (to avoid token limits)
    sample_size = min(100, len(X_train))
    sample_indices = np.random.choice(len(X_train), sample_size, replace=False)
    
    prompt = f"""
    You are a data scientist analyzing cantine meal consumption patterns. 
    Below is historical data with features and the number of meals consumed (target).
    
    Historical data (first {sample_size} samples):
    Features: {X_train.iloc[sample_indices].to_dict()}
    Target: {y_train.iloc[sample_indices].tolist()}
    
    Based on this data and your knowledge of factors affecting meal consumption:
    1. What are the most important factors that affect meal consumption?
    2. How do different weather conditions affect consumption?
    3. How do holidays, exams, and religious periods affect consumption?
    4. What patterns have you noticed in the data?
    
    Please provide specific insights that would help in forecasting future meal consumption.
    """
    
    return prompt

def forecast_with_azure_openai(X_train, y_train, future_dates_features):
    """
    Use Azure OpenAI to help with forecasting
    """
    # First, get insights from the model
    prompt = create_prompt_for_analysis(X_train, y_train, future_dates_features)
    
    try:
        response = client.chat.completions.create(
            model=AZURE_AOAI_MODEL_DEPLOYMENT_NAME,
            messages=[
                {"role": "system", "content": "You are a data scientist specializing in time series forecasting and pattern recognition."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000
        )
        
        insights = response.choices[0].message.content
        print("Insights from Azure OpenAI:")
        print(insights)
        
    except Exception as e:
        print(f"Error getting insights from Azure OpenAI: {e}")
        insights = "No insights available"
    
    # For actual forecasting, we'll use a traditional model but informed by the insights
    # We'll use a Gradient Boosting model which can capture complex relationships
    from sklearn.ensemble import GradientBoostingRegressor
    from sklearn.metrics import mean_absolute_error
    
    model = GradientBoostingRegressor(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=3,
        random_state=42
    )
    
    model.fit(X_train, y_train)
    
    # Make predictions
    predictions = model.predict(future_dates_features)
    
    return predictions, insights, model

# Prepare future dates for forecasting (next 7 days)
def prepare_future_data(start_date, days=7):
    """
    Prepare feature data for future dates based on known information
    """
    future_dates = [start_date + timedelta(days=i) for i in range(days)]
    
    future_data = []
    for date in future_dates:
        # These are the features we know or can get forecasts for
        day_features = {
            'jour': date.day,
            'mois': date.month,
            'annee': date.year,
            'jour num': date.isoweekday(),  # Monday=1, Sunday=7
            'week_of_year': date.isocalendar().week,
            'is_weekend': 1 if date.isoweekday() >= 6 else 0
        }
        
        # Add placeholders for other features (these would come from external sources)
        # For a real implementation, you would get weather forecasts from an API
        day_features.update({
            'temperature': 25,  # Placeholder - get from weather forecast
            'vitesse du vent': 10,  # Placeholder - get from weather forecast
            'clair': 1,  # Placeholder - get from weather forecast
            'nuageux': 0,  # Placeholder - get from weather forecast
            'fortement nuageux': 0,  # Placeholder - get from weather forecast
            'pluie': 0,  # Placeholder - get from weather forecast
            'conge scolaires': 0,  # Placeholder - need to get school calendar
            'jeunes': 0,  # Placeholder - need religious calendar
            'BEM': 0,  # Placeholder - need exam calendar
            'BAC': 0,  # Placeholder - need exam calendar
        })
        
        # Add hijri month dummies (would need to calculate hijri date)
        # For simplicity, we'll assume all zeros - in practice you'd need a hijri calendar
        hijri_months = [col for col in X_train.columns if col.startswith('hijri_month_')]
        for month in hijri_months:
            day_features[month] = 0
        
        future_data.append(day_features)
    
    return pd.DataFrame(future_data)

# Get tomorrow's date as start date for forecasting
start_date = datetime.now().date() + timedelta(days=1)
future_dates_features = prepare_future_data(start_date)

# Make sure future_dates_features has the same columns as X_train
for col in X_train.columns:
    if col not in future_dates_features.columns:
        future_dates_features[col] = 0

future_dates_features = future_dates_features[X_train.columns]

# Forecast using our hybrid approach
predictions, insights, model = forecast_with_azure_openai(X_train, y_train, future_dates_features)

# Display results
print("\nForecast for the next 7 days:")
for i, date in enumerate([start_date + timedelta(days=i) for i in range(7)]):
    print(f"{date}: {predictions[i]:.0f} meals")

# Since we need to order a fixed number daily, let's find the optimal order quantity
# that minimizes both waste and shortage
optimal_order = np.median(predictions)  # You might want to use a different strategy
print(f"\nRecommended fixed daily order quantity: {optimal_order:.0f} meals")

# Optional: Feature importance analysis
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nTop 10 most important features:")
print(feature_importance.head(10))
